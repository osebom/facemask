# -*- coding: utf-8 -*-
"""FaceMask.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yN6Du0mEE9uba11RYQJ0qmFUUMeISZNl
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout
from tensorflow.keras.optimizers import Adam
from keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
from google.colab import files

uploaded= files.upload()

!unzip data.zip

!rm data.zip

batch_size= 8 #usually a number to the power of 2, data is divided and fed in batches
epoch = 30 #number of cycles the system iterates through data, 
#usually trial and error, around 30, you look at accuracy of training and validation data, they should be increasing

#training data is for training and validation is to make sure the model is not overfitting, and is not in the training set
direct='data'
img_datagen= ImageDataGenerator(validation_split=0.2, #0.2 is 20%
                                rescale= 1/255,
                                rotation_range= 40, #degrees
                                width_shift_range=0.2,
                                height_shift_range=0.2,
                                zoom_range= 0.2,
                                horizontal_flip= True,
                                fill_mode= 'nearest') #generate different version of your data (i.e: inverted, rotated, etc.)

#Create training and validation arrays
train_generator= img_datagen.flow_from_directory (direct, 
                                                  target_size= (70,70),
                                                  batch_size=batch_size,
                                                  color_mode="rgb",
                                                  class_mode="binary",
                                                  shuffle= True,
                                                  seed= 42,
                                                  subset= 'training'
                                                  )

valid_generator= img_datagen.flow_from_directory (direct, 
                                                  target_size= (70,70),
                                                  batch_size=batch_size,
                                                  color_mode="rgb",
                                                  shuffle= True,
                                                  seed= 42,
                                                  subset= 'validation'
                                                  )

#generate a batch of image (or features) and labels
imgs, labels= next(train_generator)
#place images into images array and the labels are the zeroes and ones

#plotting function
def plotImages(images_arr):
  fig, axes= plt.subplots(1, batch_size, figsize=(20,20))
  axes=axes.flatten()

  for img, ax in zip(images_arr, axes):
    ax.imshow(img)
    ax.axis('off')
  plt.tight_layout()
  plt.show()

plotImages(imgs)
print(labels)

#Prep is done, now we can build the model

#Build the model
#first we need extraction layers (to extract images to feed as input), then classification layers
#In extraction, there is convolutional layer and image layer, convolutional extracts features from the images, then we have the max pool layer, to track the size
#This nextwork has 3 convolutional layers, and each layer must be followed by a max pool
#Then we have flatten layer converts everything into a 1-D vector and passes it to the output
#Dense is outout layer, there can be 2 Dense layers, one would be taking from the last Conv2D layer, on the other will be for classifying 0 or 1

model= Sequential([Conv2D(filters= 32, kernel_size= (3,3), activation= 'relu', padding='same', input_shape=(70,70,3)),
                   MaxPool2D(pool_size=(2,2), strides= 2),

                   Conv2D(filters= 32, kernel_size= (3,3), activation= 'relu', padding='same'),
                   MaxPool2D(pool_size=(2,2), strides= 2),

                   Conv2D(filters= 64, kernel_size= (3,3), activation= 'relu', padding='same'),
                   MaxPool2D(pool_size=(2,2), strides= 2),
                   
                   Flatten(),

                   Dense(units=64,activation='relu'),
                   Dense(units=1,activation='sigmoid') #sigmoid is for classifying binary, if more then you use softmax
                   
                   ])
                   
model.summary()

#Training Model
#But first we have to compile the model
#We need to set the parameters we want to keep track of (loss, accuracy) and we also set its learning rate

model.compile(optimizer= Adam(learning_rate=0.0001), loss= 'binary_crossentropy', metrics= ['accuracy'])

#TRAIN

history = model.fit(train_generator, epochs= epoch, validation_data= valid_generator, batch_size= batch_size)

#As you progress, loss drops and accuracy and validation accuracy increases

#Plotting the loss from validation and training sets

loss_train= history.history['loss']
loss_val =history.history['val_loss']

epochplot= range(1, epoch+1)
plt.plot(epochplot, loss_train, 'g', label='Training Loss')
plt.plot(epochplot, loss_val, 'b', label='Validation Loss')
plt.title('Training vs valid loss')

plt.show()

#Testing
import numpy as np
from IPython.display import Image, display

for i in range(1,5):
  img_direct= str(i) +'.jpg'
  img_data=image.load_img(img_direct, target_size=(70,70))
  img_data= image.img_to_array(img_data)
  img_data= np.expand_dims(img_data, axis=0)

  classify = model.predict(img_data)
  display(Image(img_direct, width=150, height=150))
  if(classify[0][0]==[0]):
    print('Mask in sight')

  else:
    print('No mask in sight')

